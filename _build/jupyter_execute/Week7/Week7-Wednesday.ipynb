{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d22712ab-32d4-4a34-9ad3-5f00bfbf6f1c",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# PyTorch and Neural Networks 2\n",
    "\n",
    "[YuJa recording of lecture](https://uci.yuja.com/V/Video?v=4417722&node=14870050&a=1646074732&autoplay=1)\n",
    "\n",
    "Topics mentioned at the board (not in this notebook):\n",
    "* Importance of using activation functions to break linearity.\n",
    "* Common choices of activation functions: sigmoid and relu.\n",
    "* Concept of *one hot encoding*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "964feea1-8bf9-4fa4-b092-4951967f9510",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4828,
    "execution_start": 1645026895419,
    "source_hash": "777e8eaa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.std import tqdm, trange\n",
    "from tqdm import notebook\n",
    "notebook.tqdm = tqdm\n",
    "notebook.trange = trange\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "b25be2e0-06dd-49e3-b182-b01fe6d6ce0d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 131,
    "execution_start": 1645026944896,
    "source_hash": "3470a599",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2b5fab80-0069-4818-97ca-7abd75eb9513",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Second YouTube video on *Neural Networks* from 3Blue1Brown.  This video is on *gradient descent*.  Recommended clips:\n",
    "* 0:25-1:24\n",
    "* 3:18-4:05\n",
    "* 5:15-7:50\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4639f990-1849-43e1-a4ba-09a004d705d5",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "This is what we finished with on Monday:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "f7517bcf-4088-44f0-b6b5-1f5b0d307456",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ThreeBlue(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784,10)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        y = self.flatten(x)\n",
    "        z = self.layers(y)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate an object in this class as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wed = ThreeBlue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class (see the YuJa recording above), we gradually built up to the following code.  It was designed to match the 3Blue1Brown video's neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "678d0308-be4d-4ea6-b6d5-66be4bb2c5b0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1645028827880,
    "source_hash": "b42fb0e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ThreeBlue(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784,16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16,16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16,10),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x/255\n",
    "        y = self.flatten(x)\n",
    "        z = self.layers(y)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "86981e7a-5bb3-49a3-b930-953f3c2cd80a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1645028828820,
    "source_hash": "353affe8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "wed = ThreeBlue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the weights and biases for this neural network.  When we talk about fitting or training a neural network, we mean adjust the weights and biases to try to minimize some loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "acd5ae18-5457-44af-8ea4-4dded559f2db",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1645028862219,
    "source_hash": "800e8d26",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 784])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([16])\n",
      "torch.Size([10, 16])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in wed.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "73cf88fe-de77-4cfd-8a8d-97fd4147a639",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1645028896330,
    "source_hash": "ff029ba8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12544\n",
      "16\n",
      "256\n",
      "16\n",
      "160\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for p in wed.parameters():\n",
    "    print(p.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this is the same 13002 number which appeared in the 3Blue1Brown videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "1ce93201-db9c-4051-bfb5-90cdaac3ca0f",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1645028977475,
    "source_hash": "91e4ea66",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in wed.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even do the same thing without the square brackets.  This is secretly using a *generator expression* instead of a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "11b9e7c3-a1c0-4f0c-8232-86dc461e5c4a",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1645028989266,
    "source_hash": "90a4ed9f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13002"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in wed.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "06d805f3-f56f-408f-b4d2-a399cded3f07",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     174.796875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1645028248017,
    "source_hash": "eea77758",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreeBlue(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=16, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (3): Sigmoid()\n",
       "    (4): Linear(in_features=16, out_features=10, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the line that begins `self.layers = ` above, we were specifying that each ThreeBlue object should have a `layers` attribute.  Here is that attribute for the case of `wed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "89d03220-71ca-47c4-94b0-041174781561",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     117.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 159,
    "execution_start": 1645028307383,
    "source_hash": "6b75489a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=16, bias=True)\n",
       "  (1): Sigmoid()\n",
       "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (3): Sigmoid()\n",
       "  (4): Linear(in_features=16, out_features=10, bias=True)\n",
       "  (5): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wed.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access for example the second element of `wed.layers` using subscripting, `wed.layers[2]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=16, out_features=16, bias=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wed.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "84421baa-a9a5-441b-9517-58d8edbe606d",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1645028364513,
    "source_hash": "a4dc0b78",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wed.layers[2].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": "b640a578-5d22-42b6-b5c4-435c69c6ee43",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1645028453399,
    "source_hash": "6c33b1b9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wed.layers[2].bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Monday, we were having to divide by 255 each time we input data to our neural network.  Today, we've put that step directly into the `forward` method of the neural network; it's the line `x = x/255`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": "7397d13f-6f13-4913-9a66-34b8bb39cbbd",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     117.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 235,
    "execution_start": 1645027925083,
    "source_hash": "5cbda2e8",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5128, 0.3936, 0.5649, 0.5723, 0.5577, 0.5520, 0.5960, 0.5789, 0.4498,\n",
       "         0.5246],\n",
       "        [0.5123, 0.3924, 0.5644, 0.5736, 0.5568, 0.5522, 0.5969, 0.5799, 0.4494,\n",
       "         0.5249],\n",
       "        [0.5124, 0.3922, 0.5646, 0.5733, 0.5572, 0.5532, 0.5970, 0.5803, 0.4490,\n",
       "         0.5274]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wed(training_data.data)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": "f457b2b2-490b-46e6-8819-3a943ddbaf83",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 164,
    "execution_start": 1645029149996,
    "source_hash": "c38d27bb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = wed(training_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": "5acedcbd-af6a-43d3-95ae-b587d0952dfd",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1645029167259,
    "source_hash": "ca1e04e0",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.targets[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match the 3Blue1Brown video, we are going to convert the targets, which are integers like `5`, into length 10 vectors like `[0,0,0,0,0,1,0,0,0,0]`.  This procedure is called *one-hot encoding*, and it also exists in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": "30e21834-b9b3-4561-af67-e921fb851af0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1645029265458,
    "source_hash": "e6242156",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": "8c76ecb0-767f-4e24-a4b0-d977e0cf9bae",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     59.59375
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1645029344266,
    "source_hash": "4c1e3560",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(training_data.targets[:3], num_classes=10).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": "bcb7a5fd-a94a-4d25-84bb-5a07be31f106",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1645029381597,
    "source_hash": "3fa7e55c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true = one_hot(training_data.targets, num_classes=10).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": "75d36399-5a32-4560-8671-eece891794ce",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1645029390714,
    "source_hash": "b96addef",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Mean-Squared Error on the probabilities for this classification problem is not considered the best approach, but it is easy to understand, and we will follow this approach for now to match the 3Blue1Brown video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": "8ded52b8-edf4-4a6f-8749-3c8807984893",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1645029444008,
    "source_hash": "851002be",
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the performance of the randomly initialized model.  The output of this sort of loss function is not so easy to analyze in isolation.  The important thing is that if we can lower this number, then the model is performing better (on the training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": "fe8a6f9f-2de1-41d6-9f76-811c5f674b23",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1645029463916,
    "source_hash": "1c9066c3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2792, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to find better weights and biases using *gradient descent*.  Try to get comfortable with these steps (they can take some time to internalize)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": "f954185a-d8a1-457b-b2f1-f70c0782edde",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1645029699412,
    "source_hash": "7b1ac3d0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(wed.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There aren't yet any gradients associated with the parameters of the model (the weights and biases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": "a192dcdc-c9c0-44a6-984e-807e07bd6509",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1645029736991,
    "source_hash": "840e062f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for p in wed.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_id": "e3a2b290-245c-4868-8a9c-ba91f6ba4ef0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1645029757551,
    "source_hash": "2a393a20",
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = loss_fn(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still no gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_id": "8880f57f-09a3-4a6c-9444-0488e5f88b0e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1645029772049,
    "source_hash": "840e062f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for p in wed.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_id": "de1c5ec9-6e6d-46e1-9615-006557c7a833",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 73,
    "execution_start": 1645029802373,
    "source_hash": "f4c34168",
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line `loss.backward()` told PyTorch to compute the gradients of the loss calculation with respect to the 13002 weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cell_id": "fb71589f-b590-400e-871f-6c1400561388",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1645029828879,
    "source_hash": "840e062f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([-1.8313e-04,  6.0323e-05, -7.9682e-05,  1.3652e-04,  2.8588e-04,\n",
      "         5.4873e-05,  5.6339e-04, -4.3447e-04,  8.5402e-05,  4.7174e-05,\n",
      "         2.8684e-04,  2.4752e-04,  3.4093e-04,  1.2426e-04,  7.8342e-05,\n",
      "         3.8503e-04])\n",
      "tensor([[ 1.5513e-03,  1.4997e-03,  1.4607e-03,  1.5071e-03,  1.4121e-03,\n",
      "          1.5751e-03,  1.5298e-03,  1.5007e-03,  1.4708e-03,  1.5008e-03,\n",
      "          1.6073e-03,  1.6327e-03,  1.5269e-03,  1.4076e-03,  1.5441e-03,\n",
      "          1.3184e-03],\n",
      "        [ 2.4013e-03,  2.3361e-03,  2.2776e-03,  2.3523e-03,  2.1835e-03,\n",
      "          2.4395e-03,  2.3866e-03,  2.3222e-03,  2.2672e-03,  2.3256e-03,\n",
      "          2.4822e-03,  2.5124e-03,  2.3493e-03,  2.1990e-03,  2.4188e-03,\n",
      "          2.0566e-03],\n",
      "        [-2.2165e-06, -9.6794e-06, -2.1568e-05, -1.9828e-05, -1.8939e-05,\n",
      "         -9.7146e-06, -1.5075e-05, -4.0656e-05, -1.7720e-05,  3.4108e-09,\n",
      "         -3.3992e-05, -3.1905e-05, -2.0933e-05, -1.9765e-05, -2.4898e-05,\n",
      "         -2.6694e-05],\n",
      "        [-2.8100e-04, -2.8200e-04, -2.7381e-04, -2.9060e-04, -2.6077e-04,\n",
      "         -2.7536e-04, -2.9915e-04, -2.7826e-04, -2.6433e-04, -2.5710e-04,\n",
      "         -2.9216e-04, -2.8800e-04, -2.8381e-04, -2.6977e-04, -3.0117e-04,\n",
      "         -2.5156e-04],\n",
      "        [ 1.0721e-03,  1.0468e-03,  1.0277e-03,  1.0680e-03,  9.8862e-04,\n",
      "          1.0792e-03,  1.0801e-03,  1.0512e-03,  1.0151e-03,  1.0319e-03,\n",
      "          1.1056e-03,  1.1206e-03,  1.0652e-03,  1.0057e-03,  1.1023e-03,\n",
      "          9.3069e-04],\n",
      "        [ 5.5203e-04,  5.5129e-04,  5.4008e-04,  5.5955e-04,  5.1289e-04,\n",
      "          5.7207e-04,  5.5648e-04,  5.5705e-04,  5.2402e-04,  5.2216e-04,\n",
      "          5.8920e-04,  5.9263e-04,  5.4806e-04,  5.1084e-04,  5.7347e-04,\n",
      "          4.7725e-04],\n",
      "        [-1.0829e-03, -1.0391e-03, -1.0199e-03, -1.0541e-03, -9.7853e-04,\n",
      "         -1.0998e-03, -1.0704e-03, -1.0504e-03, -1.0328e-03, -1.0516e-03,\n",
      "         -1.1339e-03, -1.1448e-03, -1.0772e-03, -9.9053e-04, -1.0844e-03,\n",
      "         -9.3149e-04],\n",
      "        [ 4.0089e-04,  3.7560e-04,  3.5750e-04,  3.7532e-04,  3.4274e-04,\n",
      "          3.7918e-04,  3.9848e-04,  3.5818e-04,  3.5726e-04,  3.8072e-04,\n",
      "          3.8984e-04,  3.9334e-04,  3.8159e-04,  3.6648e-04,  4.0230e-04,\n",
      "          3.4276e-04],\n",
      "        [ 1.0015e-04,  1.1278e-04,  1.0807e-04,  1.1097e-04,  1.0148e-04,\n",
      "          9.9824e-05,  1.1656e-04,  1.0273e-04,  9.4862e-05,  9.2009e-05,\n",
      "          9.2207e-05,  8.7203e-05,  9.4461e-05,  1.0173e-04,  1.1096e-04,\n",
      "          9.0506e-05],\n",
      "        [-2.7376e-04, -2.6440e-04, -2.5965e-04, -2.7287e-04, -2.4827e-04,\n",
      "         -2.6744e-04, -2.7625e-04, -2.6334e-04, -2.5119e-04, -2.5872e-04,\n",
      "         -2.7264e-04, -2.7600e-04, -2.7239e-04, -2.6221e-04, -2.8732e-04,\n",
      "         -2.3753e-04],\n",
      "        [-3.0894e-05, -4.6069e-05, -5.6068e-05, -6.0372e-05, -4.7414e-05,\n",
      "         -3.2222e-05, -5.3234e-05, -5.4248e-05, -3.5233e-05, -2.8325e-05,\n",
      "         -4.0417e-05, -3.6876e-05, -3.9883e-05, -5.7270e-05, -6.4234e-05,\n",
      "         -5.3041e-05],\n",
      "        [-2.0521e-03, -1.9898e-03, -1.9339e-03, -2.0009e-03, -1.8605e-03,\n",
      "         -2.0647e-03, -2.0414e-03, -1.9682e-03, -1.9259e-03, -1.9836e-03,\n",
      "         -2.1029e-03, -2.1329e-03, -2.0004e-03, -1.8793e-03, -2.0647e-03,\n",
      "         -1.7582e-03],\n",
      "        [-1.1316e-03, -1.1034e-03, -1.0669e-03, -1.1025e-03, -1.0163e-03,\n",
      "         -1.1266e-03, -1.1373e-03, -1.0711e-03, -1.0502e-03, -1.0853e-03,\n",
      "         -1.1463e-03, -1.1481e-03, -1.0907e-03, -1.0356e-03, -1.1419e-03,\n",
      "         -9.8145e-04],\n",
      "        [ 6.4383e-04,  6.2033e-04,  5.9793e-04,  6.2632e-04,  5.6714e-04,\n",
      "          6.3456e-04,  6.4794e-04,  6.0152e-04,  5.9248e-04,  6.1108e-04,\n",
      "          6.5407e-04,  6.5323e-04,  6.2586e-04,  5.9097e-04,  6.5470e-04,\n",
      "          5.5457e-04],\n",
      "        [ 6.4822e-04,  6.2109e-04,  6.1811e-04,  6.3792e-04,  5.9188e-04,\n",
      "          6.5852e-04,  6.3653e-04,  6.2957e-04,  6.1760e-04,  6.3564e-04,\n",
      "          6.8030e-04,  6.9065e-04,  6.4661e-04,  5.9874e-04,  6.5402e-04,\n",
      "          5.7052e-04],\n",
      "        [ 1.0332e-03,  1.0129e-03,  9.8541e-04,  1.0194e-03,  9.3670e-04,\n",
      "          1.0267e-03,  1.0482e-03,  9.8933e-04,  9.5952e-04,  9.9341e-04,\n",
      "          1.0564e-03,  1.0607e-03,  9.9555e-04,  9.5971e-04,  1.0609e-03,\n",
      "          9.1640e-04]])\n",
      "tensor([ 2.9285e-03,  4.5277e-03, -4.0536e-05, -5.2834e-04,  2.0315e-03,\n",
      "         1.0567e-03, -2.0450e-03,  7.2072e-04,  1.9550e-04, -5.0986e-04,\n",
      "        -8.0033e-05, -3.8523e-03, -2.1089e-03,  1.1834e-03,  1.2280e-03,\n",
      "         1.9357e-03])\n",
      "tensor([[0.0107, 0.0118, 0.0100, 0.0125, 0.0115, 0.0129, 0.0104, 0.0088, 0.0129,\n",
      "         0.0120, 0.0106, 0.0071, 0.0137, 0.0115, 0.0074, 0.0090],\n",
      "        [0.0069, 0.0076, 0.0065, 0.0081, 0.0075, 0.0083, 0.0067, 0.0057, 0.0084,\n",
      "         0.0078, 0.0068, 0.0045, 0.0089, 0.0075, 0.0048, 0.0058],\n",
      "        [0.0119, 0.0130, 0.0111, 0.0138, 0.0128, 0.0143, 0.0115, 0.0098, 0.0143,\n",
      "         0.0133, 0.0117, 0.0078, 0.0152, 0.0128, 0.0082, 0.0100],\n",
      "        [0.0119, 0.0131, 0.0112, 0.0139, 0.0129, 0.0143, 0.0115, 0.0098, 0.0144,\n",
      "         0.0134, 0.0118, 0.0079, 0.0153, 0.0128, 0.0083, 0.0101],\n",
      "        [0.0118, 0.0129, 0.0110, 0.0137, 0.0127, 0.0141, 0.0114, 0.0097, 0.0142,\n",
      "         0.0132, 0.0116, 0.0078, 0.0151, 0.0126, 0.0081, 0.0099],\n",
      "        [0.0118, 0.0130, 0.0111, 0.0138, 0.0128, 0.0142, 0.0115, 0.0097, 0.0143,\n",
      "         0.0133, 0.0117, 0.0078, 0.0152, 0.0127, 0.0082, 0.0100],\n",
      "        [0.0124, 0.0136, 0.0116, 0.0145, 0.0134, 0.0149, 0.0120, 0.0102, 0.0150,\n",
      "         0.0139, 0.0122, 0.0082, 0.0159, 0.0133, 0.0086, 0.0105],\n",
      "        [0.0120, 0.0132, 0.0112, 0.0140, 0.0130, 0.0144, 0.0116, 0.0099, 0.0145,\n",
      "         0.0135, 0.0118, 0.0079, 0.0154, 0.0129, 0.0083, 0.0101],\n",
      "        [0.0090, 0.0099, 0.0084, 0.0105, 0.0097, 0.0109, 0.0087, 0.0074, 0.0109,\n",
      "         0.0101, 0.0089, 0.0059, 0.0116, 0.0097, 0.0062, 0.0076],\n",
      "        [0.0110, 0.0121, 0.0103, 0.0129, 0.0119, 0.0133, 0.0107, 0.0091, 0.0133,\n",
      "         0.0124, 0.0109, 0.0073, 0.0141, 0.0118, 0.0076, 0.0093]])\n",
      "tensor([0.0207, 0.0134, 0.0229, 0.0230, 0.0227, 0.0229, 0.0240, 0.0232, 0.0174,\n",
      "        0.0213])\n"
     ]
    }
   ],
   "source": [
    "for p in wed.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line adjusts the weights and biases by adding a multiple of the negative gradient.  (We are trying to minimize the loss, and the gradient points in the direction of fastest ascent, and the negative gradient points in the direction of fastest descent.)  The multiple we use is determined by the *learning rate* `lr` that we specified when we created the optimizer above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cell_id": "95a66aff-99bf-4402-aa55-352b0a024662",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1645029864947,
    "source_hash": "8a03d43",
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cell_id": "0c118ca0-a98b-4c2a-bd7c-2ddf9070aace",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     117.171875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 290,
    "execution_start": 1645029904666,
    "source_hash": "5cbda2e8",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5100, 0.3918, 0.5617, 0.5692, 0.5546, 0.5489, 0.5928, 0.5757, 0.4474,\n",
       "         0.5216],\n",
       "        [0.5095, 0.3906, 0.5612, 0.5705, 0.5537, 0.5491, 0.5936, 0.5768, 0.4471,\n",
       "         0.5219],\n",
       "        [0.5096, 0.3905, 0.5614, 0.5701, 0.5540, 0.5501, 0.5938, 0.5771, 0.4466,\n",
       "         0.5244]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wed(training_data.data)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to repeat that procedure.  Here we will repeat it 10 times, but often we will want to repeat it many more times.  What we hope is that the loss value is decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cell_id": "9f20bf91-15c8-4920-92f7-64d8efb869f0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2676,
    "execution_start": 1645030099505,
    "source_hash": "45454d0c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2767, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2741, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2717, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2692, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2668, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2644, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2620, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2597, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2574, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2551, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_true = one_hot(training_data.targets, num_classes=10).to(torch.float)\n",
    "    y_pred = wed(training_data.data)\n",
    "    loss = loss_fn(y_true,y_pred)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important thing to point out is that if we run the same code again, we won't be starting back at the beginning.  Each time we run this training procedure, it will begin where the last training procedure left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cell_id": "e0d737f6-37a8-4e6b-8d40-2aae30106986",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 25992,
    "execution_start": 1645030307420,
    "source_hash": "c2edfe7a",
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2528, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2484, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2441, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2399, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2358, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2318, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2280, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2242, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2206, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2170, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2136, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2102, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2069, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2038, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2007, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1977, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1948, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1920, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1893, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1866, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1840, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1815, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1791, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1768, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1745, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1723, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1701, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1681, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1661, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1641, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1622, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1604, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1586, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1568, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1552, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1535, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1520, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1504, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1489, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1475, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1461, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1447, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1434, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1421, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1409, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1397, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1385, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1374, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1363, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1352, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_true = one_hot(training_data.targets, num_classes=10).to(torch.float)\n",
    "    y_pred = wed(training_data.data)\n",
    "    loss = loss_fn(y_true,y_pred)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%2 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the loss is steadily decreasing.  That's the best result we can hope for.  If we were to choose a learning rate that was much too big, the performance would be very different.  Here we set `lr=500` which is much too big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "cell_id": "b38d8a40-f353-463e-9bb4-836e81bed260",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1645030387319,
    "source_hash": "353affe8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "wed = ThreeBlue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "cell_id": "fd82a166-4759-4e0c-b899-dbe0cdfb0e9d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1645030352499,
    "source_hash": "85e60caf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(wed.parameters(), lr=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "cell_id": "06157912-575a-4d05-86ea-c2c6302bb125",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 27074,
    "execution_start": 1645030389949,
    "source_hash": "c2edfe7a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2877, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_true = one_hot(training_data.targets, num_classes=10).to(torch.float)\n",
    "    y_pred = wed(training_data.data)\n",
    "    loss = loss_fn(y_true,y_pred)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "574df383-2ab3-463b-9d4d-bf2a6bc902cd",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "source": [
    "Here it improves for one iteration of gradient descent, and then it seems to get stuck."
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "f0dba5ce-bbc0-4257-b9ae-422593313087",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}